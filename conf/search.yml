version: '1.0'

title: Semantically Re-ranked ElasticSearch queries
description: |
  A drop-in replacement of an ElasticSearch endpoint that can re-rank normal
  full-text queries.

package: app.api.search
tags:
  - semanticsearch
prefix: /_search_classic

components:    # define all the building-blocks for Pipeline
  - name: FacetedDocumentStore
    type: SearchlibElasticsearchDocumentStore
    params:
      host: localhost
      index: data_searchui
      create_index: false
      content_field: "text"
      embedding_field: "embedding"
      search_fields: "*"
      name_field: "_id"

  - name: RequestClassifier
    type: ElasticSearchRequestClassifier

  - name: RawRetriever
    type: RawElasticsearchRetriever
    params:
      document_store: FacetedDocumentStore

  - name: DensePassageRetriever
    type: RawDensePassageRetriever
    params:
      # document_store: HaystackDocumentStore
      document_store: FacetedDocumentStore

  - name: TagRequestAsDeclarativeQuery
    type: Category
    params:
      category: "query:declarative"

  - name: TagRequestAsInterrogativeQuery
    type: Category
    params:
      category: "query:interrogative"

  - name: TagRequestAsKeyword
    type: Category
    params:
      category: "query:keyword"

  - name: TagRequestAsMetadata
    type: Category
    params:
      category: "request:metadata"

  - name: TagRequestAsQuery
    type: Category
    params:
      category: "request:query"

  - name: DPRequestClassifier
    type: DPRequestClassifier

  - name: QueryClassifier
    type: TransformersQueryClassifier
    params:
      model_name_or_path: shahrukhx01/bert-mini-finetune-question-detection

  - name: QuestionStatementQueryClassifier
    type: TransformersQueryClassifier
    params:
      model_name_or_path: shahrukhx01/question-vs-statement-classifier

  - name: LangDetect
    type: LangDetect

pipelines:
  - name: search
    type: Query
    nodes:
      - name: LangDetect
        inputs: [Query]

      - name: RequestClassifier
        inputs: [LangDetect]

      - name: TagRequestAsMetadata
        inputs: [RequestClassifier.output_1]

      - name: TagRequestAsQuery
        inputs: [RequestClassifier.output_2]

      - name: RawRetriever
        inputs: [TagRequestAsMetadata]

      - name: QueryClassifier
        inputs: [TagRequestAsQuery]

      - name: QuestionStatementQueryClassifier
        inputs: [QueryClassifier.output_1]

      - name: TagRequestAsKeyword
        inputs: [QueryClassifier.output_2]

      - name: TagRequestAsInterrogativeQuery
        inputs: [QuestionStatementQueryClassifier.output_1]

      - name: TagRequestAsDeclarativeQuery
        inputs: [QuestionStatementQueryClassifier.output_2]

      - name: DPRequestClassifier
        inputs: [TagRequestAsInterrogativeQuery, TagRequestAsDeclarativeQuery, TagRequestAsKeyword]

      - name: RawRetriever
        inputs: [DPRequestClassifier.output_1]

      - name: DensePassageRetriever
        inputs: [DPRequestClassifier.output_2]


# See
# https://github.com/deepset-ai/haystack/blob/master/docs/_src/api/api/pipelines.md#load_from_yaml
# for how to override from env
#
# ES document store options:
# `index`: the ES index name, by default "document"
#
# `text_field`: Name of field that might contain the answer and will therefore be
# passed to the Reader Model (e.g. "full_text"). If no Reader is used (e.g. in
# FAQ-Style QA) the plain content of this field will just be returned.
#
# `name_field`: Name of field that contains the title of the the doc
#
# `embedding_field`: per text field embeddings, default: "embedding". Name of
# field containing an embedding vector (Only needed when using a dense
# retriever (e.g. DensePassageRetriever, EmbeddingRetriever) on top)
#
# `label_index`: Name of index in elasticsearch to use for storing labels. If
# not existing yet, we will create one.
#
# faq_question_field:
#
# See the rest at:
# https://github.com/deepset-ai/haystack/blob/master/haystack/document_store/elasticsearch.py
#
# - name: Ranker
#   type: SentenceTransformersRanker
#   params:
#     model_name_or_path: cross-encoder/ms-marco-MiniLM-L-12-v2

# TODO: update query, to be like:
# {"size": 4,
# "_source": {
#     "excludes": [
#       "text_embeddings"
#     ]
#     },
#     "query": {
#
#     "function_score": {
#   "query": {
#
#
#
#
#
#
#
#     "script_score": {
#       "query": {
#
#
#
#       	"bool": {
#           "filter": [
#             {
#               "bool": {
#                 "should": [
#                   {
#                     "term": {
#                       "language": "en"
#                     }
#                   }
#                 ],
#                 "minimum_should_match": 1
#               }
#             },
#             {
#               "bool": {
#                 "should": [
#                   {
#                     "range": {
#                       "readingTime": {}
#                     }
#                   }
#                 ],
#                 "minimum_should_match": 1
#               }
#             },
#             {
#               "term": {
#                 "hasWorkflowState": "published"
#               }
#             },
#             {
#               "constant_score": {
#                 "filter": {
#                   "bool": {
#                     "should": [
#                       {
#                         "bool": {
#                           "must_not": {
#                             "exists": {
#                               "field": "expires"
#                             }
#                           }
#                         }
#                       },
#                       {
#                         "range": {
#                           "expires": {
#                             "gte": "2021-09-28T10:15:55Z"
#                           }
#                         }
#                       }
#                     ]
#                   }
#                 }
#               }
#             }
#           ]
#         }
#
#
#       },
#       "script": {
#         "source": "dotProduct(params.query_vector,'text_embeddings') + 1000",
#           "params": {
#             "query_vector": [
#               0.17094166576862335,
#             0.22060824930667877,
#           -0.25065118074417114
#               ]
#           }
#       }
#     }
#   }
#     }
#   }
# }
